{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9k3-Oh4ZtOJi"
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "VyRJDDpbt0-y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()"
      ],
      "metadata": {
        "id": "ssr3kC-ayqqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KerasClassifier(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, model_func, **kwargs):\n",
        "    self.model_func = model_func\n",
        "    self.kwargs = kwargs\n",
        "    self.model_ = None\n",
        "\n",
        "  def fit(self, x, y):\n",
        "    self.model_ = self.model_func(**self.kwargs)\n",
        "    self.model_.fit(x, y, epochs=10, batch_size=32, verbose=0)\n",
        "    return self\n",
        "\n",
        "  def predict(self, x):\n",
        "    # The argmax here converts the one-hot encoding to label format\n",
        "    return np.argmax(self.model_.predict(x), axis=1)\n",
        "\n",
        "def create_model(filters, learning_rate):\n",
        "  model = models.Sequential()\n",
        "  #define filters and convolutional layers here\n",
        "  model.add(layers.Conv2D(filters=filters, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "  #Add a maxpooling layer\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #Flatten the output and give it to a fully connected layer\n",
        "  model.add(layers.Flatten())\n",
        "  #one hidden layer maps the flattened neurons to output, 10 classes/labels\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "oW4U46iJur-h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = [16, 32]\n",
        "learning_rates = [0.001, 0.01]\n",
        "best_f1 = 0\n",
        "best_params = None\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "yTrain_encoded = to_categorical(yTrain)\n",
        "yTest_encoded = to_categorical(yTest)\n",
        "\n",
        "for filters in filters:\n",
        "  for lr in learning_rates:\n",
        "    print(f\"Testing model with {filters} filters and learning rate {lr}\")\n",
        "    f1_scores = []\n",
        "\n",
        "    for train_idx, val_idx in skf.split(xTrain, yTrain):\n",
        "      xTrain_fold = xTrain[train_idx]\n",
        "      yTrain_fold = yTrain_encoded[train_idx]\n",
        "      xVal_fold = xTrain[val_idx]\n",
        "      yVal_fold = yTrain_encoded[val_idx]\n",
        "\n",
        "      pipeline = Pipeline([\n",
        "          ('classifier', KerasClassifier(create_model, filters=filters, learning_rate=lr))\n",
        "      ])\n",
        "\n",
        "      # Fit and predict for current fold\n",
        "      pipeline.fit(xTrain_fold, yTrain_fold)\n",
        "      yPred_fold = pipeline.predict(xVal_fold)\n",
        "      # Convert y_val_fold from one-hot encoded to label format\n",
        "      new_yVal_fold = np.argmax(yVal_fold, axis=1)\n",
        "\n",
        "      f1 = f1_score(new_yVal_fold, yPred_fold, average='macro')\n",
        "      f1_scores.append(f1)\n",
        "\n",
        "    # Average F1 score for the current hyperparameters\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "    if avg_f1 > best_f1:\n",
        "        best_f1 = avg_f1\n",
        "        best_params = {'filters': filters, 'learning_rate': lr}\n",
        "\n",
        "    print(f\"Filters: {filters}, Learning rate: {lr}, Avg F1 Score: {avg_f1}\")\n",
        "\n",
        "print(f\"Best F1 Score: {best_f1} with parameters {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4CyKjiH2t3m",
        "outputId": "35f2c916-39cb-42c4-8478-62a0b4a3a646"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing model with 16 filters and learning rate 0.001\n",
            "375/375 [==============================] - 2s 5ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "Filters: 16, Learning rate: 0.001, Avg F1 Score: 0.9677172478241701\n",
            "Testing model with 16 filters and learning rate 0.01\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 2s 6ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "Filters: 16, Learning rate: 0.01, Avg F1 Score: 0.8839648475810149\n",
            "Testing model with 32 filters and learning rate 0.001\n",
            "375/375 [==============================] - 2s 5ms/step\n",
            "375/375 [==============================] - 2s 5ms/step\n",
            "375/375 [==============================] - 2s 6ms/step\n",
            "375/375 [==============================] - 2s 5ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "Filters: 32, Learning rate: 0.001, Avg F1 Score: 0.9695670108382286\n",
            "Testing model with 32 filters and learning rate 0.01\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 3s 7ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "375/375 [==============================] - 2s 4ms/step\n",
            "Filters: 32, Learning rate: 0.01, Avg F1 Score: 0.8821839928790702\n",
            "Best F1 Score: 0.9695670108382286 with parameters {'filters': 32, 'learning_rate': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training with the best parameters\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', KerasClassifier(create_model, filters=32, learning_rate=0.001))\n",
        "])\n",
        "\n",
        "# Fit\n",
        "pipeline.fit(xTrain, yTrain_encoded)\n",
        "# Predict on the test data\n",
        "yPred = pipeline.predict(xTest)\n",
        "# Convert y_test from one-hot encoded to label format\n",
        "new_yTest = np.argmax(yTest_encoded, axis=1)\n",
        "f1_score(new_yTest, yPred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsCUe1bOW-0J",
        "outputId": "a5f8e33f-3ed8-4122-a003-2ed68708ff74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97435846987261"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best CNN has the parameter:\")\n",
        "print(f\"Number of filters = 32\")\n",
        "print(f\"Number of learning rate = 0.001\")\n",
        "print(f\"Corresponding f1score = 0.97435846987261\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz2FlM8uV428",
        "outputId": "0f13619a-6ba6-4bcd-bb6e-932c50f05492"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best CNN has the parameter:\n",
            "Number of filters = 32\n",
            "Number of learning rate = 0.001\n",
            "Corresponding f1score = 0.97435846987261\n"
          ]
        }
      ]
    }
  ]
}